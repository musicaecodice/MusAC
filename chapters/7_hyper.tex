\chapter{Mixed music and hyper-instruments}\label{mixed-music-and-hyper-instruments}

\section{Framework and historical context}\label{framework-and-historical-context}

Mixed music combines acoustic instruments and electronic elements.

Two different musical contexts:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item sound and formal augmentation (live composing).
\item acoustic instruments augmentation (hyper-instruments).
\end{enumerate}

For both of them we can do it in two ways:

\begin{itemize}
\tightlist
\item superimposing pre-composed electronic sounds and acoustic instruments.
\item acoustic instruments real-time sound processing.
\end{itemize}

For both we have usually:

\begin{itemize}
\tightlist
\item one electronic performer.
\item one sound director.
\item one or more instrumental performers.
\end{itemize}

\subsection{Sound and formal augmentation}\label{sound-and-formal-augmentation}

In this context we can:
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item design a chamber music work for one or more acoustic instruments whose sounds develop immersed in a sound background created by electronics (virtual orchestration and scoring) as in Dai Fujikura - \href{http://www.musicaecodice.it/gitmedia/emc/7_media/fuji.mp3}{Prism spectra} (2007) - extract.

If we want to do it:

\begin{itemize}
\tightlist
\item with pre-composed electronic sounds (soundfiles) there are different configurations:
      \begin{itemize}
      \tightlist
      \item fixed electronic sounds - fixed intrumental part.
      \item fixed electronic sounds - improvised instrumental part.
      \item improvised electronics - fixed intrumental part.
      \item improvised electronics - improvised instrumental part.
      \end{itemize}
      Technical implementation for this mode is explained in the \textit{Live playback and synthesis} (\ref{live-playback-and-synthesis}) paragraph of the previous chapter.

\item in real-time the main sound processing techniques are:
      \begin{itemize}
      \tightlist
      \item accumulation of musical materials \(\rightarrow\) delay lines with or without feedback and/or transpositions.
      \item iteration of rhythmic-melodic patterns \(\rightarrow\) loop machines and live recording-playback systems.
      \item freeze sounds \(\rightarrow\) create fixed or continuously evolving harmonic fields-sound backgrounds.
      \end{itemize}
      Technical implementations are presented in \textit{Classic live-electronics sound processing} (\ref{classic-live-electronics-sound-processing}) paragraph.
\end{itemize}

\item change the perception of a place by modifying its acoustic characteristics:
      \begin{itemize}
      \tightlist
      \item within a composition as in Luigi Nono - \href{http://www.musicaecodice.it/gitmedia/emc/7_media/nono.mp3}{A Pierre. Dell'Azzurro Silenzio, Inquietum} (1985) for doublebass flute, doublebass clarinet and live electronics - extract.
      \item in the creation of a sound art installation as in David Tudor - \href{http://www.musicaecodice.it/gitmedia/emc/7_media/rainforest1.mp4}{Rainforest} (1973) - extract.
     \end{itemize}

Here the focus is on type of sound diffusion systems.

We talk about this topic in the \textit{Common topics to think about} (\ref{common-topics-to-think-about}) section.

\end{enumerate}

\subsection{Augmentation of acoustic instruments}\label{augmentation-of-acoustic-instruments}

Hyper-instruments are based on the goal of designing expanded musical instruments using technology to give extra power to intrumental performers. 

The first works of this type were created in the 1960s in the same studios that saw the birth of early electronic music on tape (WDR - Cologne and the RAI Phonology Studio in Milan).

Mainly they were pieces for solo instrument or small ensemble and magnetic tape.

The magnetic tape part usually contained processed or simply assembled acoustic instrumental sounds and/or synthesis sounds as in Bruno Maderna - \href{http://www.musicaecodice.it/gitmedia/emc/7_media/maderna.mp3}{Musica su due dimensioni} (1958) for flute, cymbal and tape - extract or Karlheinz Stockhausen - \href{http://www.musicaecodice.it/gitmedia/emc/7_media/konta.mp3}{Kontakte} (1958-60) for Piano, percussion and 4 channels tape - extract.

In 1976 Luigi Nono wrote with the pianist Maurizio Pollini \href{http://www.musicaecodice.it/gitmedia/emc/7_media/sofferte.mp3}{...sofferte onde serene} for piano and magnetic tape where the magnetic tape creates a virtual piano alter ego.

Beginning in 1975 Giuseppe Di Giugno at IRCAM in Paris began development of digital processors: 4A, 4B, 4C, and in 1981 the very powerful 4X system.

The musical workstation 4X is one of the first computer tools that enables a musician to digitally manipulate sounds in real-time. 

Pierre Boulez is the first to use the 4X in his work \href{http://www.musicaecodice.it/gitmedia/emc/7_media/repons.mp3}{Répons} (1981) for six solistes, chamber ensemble and live-electronics - extracts.

Since the early 1990s with the advent of personal computers and new software dedicated to real-time sound synthesis and processing (Max/MSP, Pure Data, SuperCollider, Chuck, etc.) up to the present day, this musical field has been explored on a vast scale both musically and technologically.

The focus is on designing computer systems (sensors, signal processing, and software) that measure and interpret human expression and feeling as well as on exploring the appropriate modalities and innovative content of interactive art.

Few examples.

Yan Maresz - \href{http://www.musicaecodice.it/gitmedia/emc/7_media/metal.mp3}{Metallics} (1995) for trumpet and live electronics - extract.

Fausto Romitelli - \href{http://www.musicaecodice.it/gitmedia/emc/7_media/trash.mp3}{Trash TV Trance} (2002) for electric guitar and live electronics - extract.

Georg Hajdu - \href{http://www.musicaecodice.it/gitmedia/emc/7_media/kali.mp3}{Just Her - Jester - Gesture} (2010) for kalimba and live electronics - extract.

In last years also the composer/performer body became an instrument for live processing sounds.

Marco Donnarumma - \href{http://www.musicaecodice.it/gitmedia/emc/7_media/donnarumma1.mp4}{Corpus Nil} (2016)

\subsection{Common topics to think about}\label{common-topics-to-think-about}

\begin{itemize}
\tightlist
\item music and sound relationship between acoustic and electronic parts.
  \begin{itemize}
  \tightlist
  \item musical and timbre coherence.
  \item musical and timbre contrast.
  \end{itemize}
\item musical and physical gestures.
  \begin{itemize}
  \tightlist
  \item strictly connected with previous point.
  \item acousmatic like approach \(\rightarrow\) no relation to the historicized instrumental timbre and to traditional instrumental techniques and sound morphologies.
  \item evident augmented musical gestures \(\rightarrow\) clear cause-effect relationship or mickey mouse effect (usually short time).
  \item masked augmented musical gestures \(\rightarrow\) no preceptive relationship between cause and effect (usually long time).
  \end{itemize}
\item direction of sounds and type of sound diffusion systems.
  \begin{itemize}
  \tightlist
  \item strictly connected with previous points.
  \item front diffusion systems \(\rightarrow\) mono or stereo pop concert like.
  \item immersive systems \(\rightarrow\) acoustic fields (quadriphonic, octophonic, ambisonic, wavefield synthesis, etc.).
  \item discrete diffusion systems \(\rightarrow\) speaker as musical instrument (acousmonium, laptop orchestra, etc.). 
  \end{itemize}
\item timbre and visual recognition of the sound source.
  \begin{itemize}
  \tightlist
  \item strictly connected with previous points.
  \item the player is on a stage and audience see it and the way he produce sounds.
  \end{itemize}
\item choice between pre composed electronic parts (sound files) or live processing.
  \begin{itemize}
  \tightlist
  \item first choice \(\rightarrow\) pre-composed sounds (soundfiles triggering).
  \item we should choose live processing only when we don't want precision in the execution and the aesthetic of the work need uncontrollable margins of variation between different executions.
  \item motivations must be musical and not tied to technological fetishes.
  \end{itemize}
\end{itemize}

\section{Software model}\label{software-model}

In a live-electronic patch we have four types of intruments:

\begin{itemize}
\tightlist
\item sound (audio) sources.
    \begin{itemize}
    \tightlist
    \item external \(\rightarrow\) mics, line inputs.
    \item internal \(\rightarrow\) oscillators.
    \end{itemize}
\item control sources. 
    \begin{itemize}
    \tightlist
    \item external  \(\rightarrow\) midi, osc, hid, sensors, etc.
    \item internal  \(\rightarrow\) source signals, oscillators, sequencer.
    \end{itemize}
\item recorders or analyzers.
\item sound processors. 
    \begin{itemize}
    \tightlist
    \item FX
    \item panners and spats.
    \end{itemize}
\end{itemize}

Set input and ouput audio connections (before Server boot).

\begin{lstlisting}[frame=single, caption=Server settings model] 
ServerOptions.devices; // Array with all connected audio devices
s.options.inDevice_("Microfono MacBook Air"); // set input device
s.options.outDevice_("Auricolari esterni");   // set output device
s.options.numInputBusChannels_(1);            // set number of input channels
s.options.numOutputBusChannels_(8);           // set number of ouput channels
\end{lstlisting} 

\begin{center}
\includegraphics[scale=0.7]{live.png}
\end{center}

As example:
\begin{itemize}
\tightlist
\item one ring modulator.
\item one recorder (click any computer key to start recording).
\item one automatic buffer player (scratcher).
\end{itemize}

\begin{lstlisting}[frame=single, caption=Live electronics model] 
s.waitForBoot{
// ---------------------------------- BUFFERS 
Buffer.freeAll;                                                         
//~bfile = Buffer.read(s, "folder/file.wav".resolveRelative);  
~blive = Buffer.alloc(s, s.sampleRate * 6, 1); // Live source Buffer
s.sync;       // wait until commands have been completed.
// --------------------------------- SYNTHDEFS 
SynthDef(\mic, {arg busIn=0,busOut=0,amp=0;   // sig In --> Bus
                    var sig;
                    sig = SoundIn.ar(busIn) * amp.lag;
                    sig = LeakDC.ar(sig);
                Out.ar(busOut,sig)
                }).add;
SynthDef(\sch, {arg buf=0, amp=0, pos=0, pan=0, busOut=0;
                var pnt, sig;
                    pnt = Lag.kr(pos.linlin(-1,1,0,BufFrames.kr(buf)),0.2);
                    sig = BufRd.ar(1, buf, K2A.ar(pnt));
                    sig = Pan2.ar(sig * amp, pan);
                Out.ar(busOut, sig)
                }).add;
SynthDef(\recOne,{arg buf=0, busIn=0;        // Bus --> Buffer
                  var in;
                      in = In.ar(busIn, 1);
                      RecordBuf.ar(in, buf, loop:0, doneAction:2);
                  }).add;
SynthDef(\ksig,{arg freq=1, busOut=0;        // control sig --> Bus
                var sig;
                    sig = LFNoise1.ar(1);
                    Out.ar(busOut, sig)
                }).add;
SynthDef(\ring, {arg busIn=0, busOut=0,      // Bus In --> Bus Out (FX)
                     idx=0, fmod=400, amp=0, pan=0; 
                 var port, mod;
                     port  = In.ar(busIn, 1) * amp.lag;
                     mod   = SinOsc.ar(fmod.linlin(-1,1,400,1000)) * idx.unipolar;
                     port  = Pan2.ar(port * mod, pan);
                 Out.ar(busOut, port)
                 }).add;
s.sync;     
// ----------------------------- BUSES AND GROUPS 
~mic1.free;
~mic2.free;
~mic1 = Bus.audio(s,1);   
~mic2 = Bus.audio(s,1);   
~ksig = Bus.audio(s,1);

~micGrp = Group.new;            // sources
~ksiGrp = Group.after(~micGrp); // control signals 
~recGrp = Group.after(~ksiGrp); // recorder and/or analyzers
~outGrp = Group.after(~recGrp); // fx and/or panning
s.sync;   
// ---------------------------------- SYNTHS
Synth(\mic,   [\busIn, 0, \amp,1, \busOut, ~mic1], ~micGrp); 
Synth(\sch,   [\buf, ~blive, \amp,1, \pos, ~ksig.asMap, \busOut, 0], ~micGrp); 
Synth(\ksig,  [\busOut, ~ksig, \freq, 5], ~ksiGrp); 
Synth(\ring,  [\busIn, ~mic1, \busOut, 0, 
               \idx, ~ksig.asMap, \fmod, ~ksig.asMap, 
               \amp, 1, \busOut, 0], ~outGrp); 
// ------------------------------------ GUI 
w = Window.new(\key);
w.alwaysOnTop_(true);
w.front;
// -------------------------------- MIDI OSC HID
MIDIClient.init;
MIDIIn.disconnectAll;
MIDIIn.connectAll;

// MIDIFunc.trace(true);
// MIDIFunc.trace(false);

MIDIdef.cc(\rec, {arg val, ccn;
                      if(val==127) 
			          {Synth(\recOne, [\busIn, ~mic1, \buf, ~blive], ~recGrp); 
                       "Recording Buffer".postln}
                  }, 0);
w.view.keyDownAction_({arg ...args;
                       Synth(\recOne, [\busIn, ~mic1, \buf, ~blive], ~recGrp); 
                       "Recording Buffer".postln;
                       });
s.sync;
s.meter;
s.plotTree;
}
\end{lstlisting} 

\begin{lstlisting}[frame=single] 
~blive.plot;
s.freeAll;
\end{lstlisting} 

\subsection{Routing signals}\label{routing-signals}
One of the main aspects of a live electronics patch is the the signals routing.

In SuperCollider we can organize it through In, Out, Bus and Group objects.

\subsubsection{In/Out}\label{in-out}
Let's define two Synths to test connections:

\begin{itemize}
\tightlist
\item source.
\item sound processor (fx reverb).
\end{itemize}

\begin{lstlisting}[frame=single] 
SynthDef(\source_1, {arg busOut=0, den=2, dur=0.8; // Out mono
                     var trig,sig,env;
                         trig = Dust.ar(den);
                         sig  = Saw.ar(TRand.ar(70,82,trig).midicps);
                         env  = Decay2.ar(trig,0.02,dur-0.02);
                         sig  = sig * env; 
                     Out.ar(busOut, sig); // Out.ar(bus, sig)
                     }).add;

SynthDef(\rev, {arg busIn=0, busOut=0; // In + Out mono
                var sig, rev;
                    sig = In.ar(busIn, 1);  // In.ar(bus, n_channels)
                    rev = FreeVerb.ar(sig,0.5,0.8,0.7);
                Out.ar(busOut, rev)
                }).add;
\end{lstlisting} 

Dynamic bus changes \(\rightarrow\) clicks!

\begin{lstlisting}[frame=single] 
a = Synth(\rev, [\busIn, 20, \busOut, 0]);
b = Synth(\source_1, [\busOut,  20]);
b.set(\busOut, 0); 
a.free; b.free;
\end{lstlisting} 

To acquire input signals from public buses \(\rightarrow\) \textit{SoundIn.ar()}.

\begin{lstlisting}[frame=single] 
SynthDef(\mic, {arg busIn=0, busOut=0, amp=0;
                var sig;
                    sig  = SoundIn.ar(busIn, amp.lag);
                    sig  = LeakDC.ar(sig);   // remove DC offset
                Out.ar(busOut, sig)
                }).add
\end{lstlisting} 

As exemple plug it in a reverber.
\begin{lstlisting}[frame=single] 
a = Synth(\rev, [\busIn, 20, \busOut, 0]);
b = Synth(\mic, [\busOut,  20, \amp, 1]);
a.free; b.free;
\end{lstlisting} 


\subsubsection{Public vs private buses}\label{public-vs-private-buses}

Two Bus types:

\begin{itemize}
\tightlist
\item public $\rightarrow$ connected to the outside world (soundcard).
\item private $\rightarrow$ only for internal signals routing.
\end{itemize}

Do not use public buses for internal routing.

Few useful informations:

\begin{lstlisting}[frame=single] 
s.options.numAudioBusChannels;  // default --> 1024
s.options.numInputBusChannels;  // public
s.options.numOutputBusChannels; // public
s.options.firstPrivateBus;      // first private bus idx 
\end{lstlisting} 

The \textit{Bus} Class only assigns \textit{private} buses.

It's better to specify the modifier name (FX send) as the label rather than the output signal name.

\begin{lstlisting}[frame=single] 
~revBus = Bus.audio(s, 1); // Server, n_channels
~revBus.index;             

a = Synth(\rev, [\inBus, ~revBus, \outBus, 0]); 
b = Synth(\source_1, [\outBus,  ~revBus]);

a.free;b.free;
\end{lstlisting} 

Useful Bus commands.

\begin{lstlisting}[frame=single] 
~revBus.index;      
~revBus.numChannels; 
~revBus.rate;       
~revBus.free;      
\end{lstlisting} 

If source is stereo or multichannel we must to specify the number of channels.

\begin{lstlisting}[frame=single] 
SynthDef(\source_2, {arg busOut=0, den=2, dur=0.8;
                     var trig,sig,env;
                         trig = Dust.ar(den);
                         sig  = Saw.ar(TRand.ar(70,82,trig).midicps);
                         env  = Decay2.ar(trig,0.02,dur-0.02);
                         sig  = sig * env;
                         sig  = Pan2.ar(sig, LFNoise1.ar(10)); // Pan random
                     Out.ar(busOut, sig)
                     }).add;

SynthDef(\rev2, {arg busIn=0, busOut=0;
                 var sig, rev;
                     sig = In.ar(busIn, 2);  // two channels
                     rev = FreeVerb.ar(sig,0.5,0.8,0.7);
                 Out.ar(busOut, rev)
                 }).add;

~revBus1 = Bus.audio(s, 2); // two channels bus
~revBus1.index;            

a = Synth(\rev2,     [\busIn,  ~revBus1, \busOut, 0]);
b = Synth(\source_2, [\busOut, ~revBus1]);

b.set(\busOut,0);  // direct Out (without reverber)
b.set(\busOut, ~revBus1); 
s.freeAll;
\end{lstlisting} 

\subsubsection{Creation order rules and Groups}\label{creation-order-rules-and-groups}

Synths that receive an input signal must be created before those that send it. 

Look at the plot tree.

It work.

\begin{lstlisting}[frame=single] 
s.plotTree;

a = Synth(\rev2,     [\inBus,  ~revBus1, \outBus, 0]); // IN + OUT
b = Synth(\source_2, [\outBus, ~revBus1]);             // only OUT

a.free;b.free;
\end{lstlisting} 

It does not work.

\begin{lstlisting}[frame=single] 
b = Synth(\source_2, [\outBus, ~revBus1]);             // only OUT
a = Synth(\rev2,     [\inBus,  ~revBus1, \outBus, 0]); // IN + OUT

a.free;b.free;
\end{lstlisting} 

This happens because the server by default creates a head-to-tail order.  

The last Synth created is placed at the top.

We can force creation to always be at the bottom with arguments:

\begin{lstlisting}[frame=single] 
b = Synth(\source_2, [\outBus, ~revBus1]);
a = Synth(\rev2,     [\inBus,  ~revBus1, \outBus, 0],  s, 'addToTail');

a.free;b.free;
\end{lstlisting} 

Further options in the Server help file.

We can simplify the structure by using Groups.

Groups are containers for Nodes and Synths.

When we launch SuperCollider the default Group is create (look at the node tree).

As we saw in the software model proposed at the beginning of the section we can create further Groups within the main one and place the Synths within one or the other.

\section{Feature extraction as control signals}\label{feature-extraction-as-control-signals}

In a paragraph of previous chapter (\ref{control-signals}) we saw that control signals can:
\begin{itemize}
\tightlist
\item come from external sources (MIDI, OSC, HID, etc.).
\item be generated by low-frequency oscillators (LFO).
\end{itemize}

We also saw the main possible operations:
\begin{itemize}
\tightlist
\item scale them to a new range. 
\item smooth them. 
\item convert them between different typologies.
\item map them to any parameter of any sound synthesis or processing technique.
\end{itemize}

We can apply the same techniques to transform an input audio signal into a control signal.

The techniques commonly used are:
\begin{itemize}
\tightlist
\item envelope following.
\item pitch following.
\item onset detection.
\item spectral analyses (FFT).
\end{itemize}

Let's define a SynthDef for source, Buses and Groups.

\begin{lstlisting}[frame=single] 
s.waitForBoot{
SynthDef(\mic, {arg busIn=0, busOut=0, amp=0;
                var sig;
                    sig = SoundIn.ar(busIn) * amp.lag;
                    sig = LeakDC.ar(sig);
                Out.ar(busOut,sig)
                }).add;
s.sync;
~micGrp   = Group.new;             // Gruppo sources
~featGrp  = Group.after(~micGrp);  // Gruppo analisi
~playGrp  = Group.after(~featGrp); // Gruppo synth
s.sync;
s.meter;
s.plotTree;
};
\end{lstlisting} 

\subsection{Envelope follower}\label{envelope-follower}

Analysis of amplitude envelope (unipolar) from an incoming audio signal (bipolar).

In SuperCollider we can use \textit{Amplitude.ar()} UGens.

\begin{lstlisting}[frame=single, caption=Envelope follower models] 
// continuos
SynthDef(\efol1, {arg busIn=0, busOut=0, atk=0.001, dec=0.01;
                  var sig, amp;
                      sig = In.ar(busIn,1);
                      amp = Amplitude.ar(sig,atk,dec);
                  Out.ar(busOut,amp)
                  }).add;
// trigger
SynthDef(\efol2, {arg busIn=0, busOut=0, atk=0.001, dec=0.01,
                      thresh=0.3, dur=0.1;
                  var sig, amp, trig;
                      sig  = In.ar(busIn,1);
                      amp  = Amplitude.ar(sig,atk,dec);
                      trig = Trig1.ar(amp > thresh, dur); // Trigger
                  Out.ar(busOut, [amp, trig]);            // two channels

			// Server --> Interpreter

	              SendTrig.ar(trig,
	                          100,  // trigger id (if more than 1)
	                          amp); // signal to send
	              }).add;
// with noise gate
SynthDef(\efol3, {arg busIn=0, busOut=0, atk=0.01, dec=0.01, thresh=0.3;
	                var sig, env;
	                    sig = In.ar(busIn, 1);
	                    sig = Compander.ar(sig, sig, thresh, 10, 1, 0.01, 0.2);
	                    env = Amplitude.ar(sig, atk,dec);
	                Out.ar(busOut, [env, env.pow(0.5)])     // power...
	                }).add;
\end{lstlisting} 

Continuos mapping example.

\begin{lstlisting}[frame=single] 
SynthDef(\noise, {arg busIn=0, busOut=0, pan=0;
                  var sig, env;
                      sig = PinkNoise.ar;
                      env = In.ar(busIn, 1); // from envelope follower
                      sig = sig * env;
                      sig = Pan2.ar(sig, pan);
                  Out.ar(busOut, sig)
	              }).add;

~featureBusIn  = Bus.audio(s, 1);  // Bus signal In
~featureBusOut = Bus.audio(s, 1);  // Bus featured values 

~envf   = Synth(\efol1, [\busIn,~featureBusIn,
                         \busOut,~featureBusOut,
                         \dec,0.6], ~featGrp);
~player = Synth(\noise, [\busIn, ~featureBusOut, 
                         \busOut,0], ~playGrp);
~monitor  = ~featureBusOut.scope;

c.set(\atk,0.1,\dec,0.2);  // try to change values
s.defaultGroup.deepFree;   // Clear Synths and Bus but not Groups
\end{lstlisting} 

Trigger mapping example.

\begin{lstlisting}[frame=single] 
SynthDef(\sine, {arg busIn=0, busOut=0;
                 var sig, gate, env;
                     gate = In.ar(busIn, 2);                         // 2 channels
                     env  = EnvGen.kr(Env.perc, gate[1]);            // switch
                     sig  = SinOsc.ar(TRand.ar(500,1000,gate[1]));   // trig
                     sig  = sig * env;
                     sig  = Pan2.ar(sig, gate[0].linlin(0,1,-1,1)); // continuos
                 Out.ar(busOut, sig)
                 }).add;

~featureBusIn  = Bus.audio(s, 1);  // Bus signal In
~featureBusOut = Bus.audio(s, 1);  // Bus featured values 

~source  = Synth(\mic, [\busIn,0, \busOut, ~featureBusIn, \amp,1], ~micGrp); 
~envf    = Synth(\efol2, [\busIn,~featureBusIn,
                          \busOut,~featureBusOut,
                          \dec,0.6,\thresh, 0.1,\dur,0.2], ~featGrp);
~player  = Synth(\sine,  [\busIn,~featureBusOut,
                          \busOut,0], ~playGrp);
~monitor = OSCFunc.new({arg msg; msg.postln},'/tr', s.addr); // from Server...

~envf.set(\thresh,0.1,\dur,0.1); // try to change threshold
s.defaultGroup.deepFree;       
\end{lstlisting} 

In some situations it may be useful to insert a noise gate before the envelope following.

Noise gate \(\rightarrow\) if signal in under a threshold is cutted (UGen Compander).

\begin{lstlisting}[frame=single] 
SynthDef(\saw, {arg busIn=0, busOut=0;
                var sig, env;
                    env  = In.ar(busIn, 1);  // only first bus channel 
                    sig  = Saw.ar([560,563]);
                    sig = sig * env * 0.5;
                Out.ar(busOut, sig)
                }).add;

~featureBusIn  = Bus.audio(s, 1);  // Bus signal In
~featureBusOut = Bus.audio(s, 1);  // Bus featured values 

~source = Synth(\mic, [\busIn,0, \busOut, ~featureBusIn, \amp,1], ~micGrp); 
~envf   = Synth(\efol3, [\busIn,~featureBusIn,
                         \busOut,~featureBusOut,
                         \dec,0.6,\thresh, 0.001,\dur,0.2], ~featGrp);
~player = Synth(\saw,   [\busIn,~featureBusOut,
                         \busOut,0], ~playGrp);

s.defaultGroup.deepFree;     
\end{lstlisting} 

More musically interesting examples are illustrated in the paragraph on real-time synthesis and processing techniques.

Few ideas:

\begin{itemize}
\tightlist
\item mix synthesized sounds that react to the envelope follower with the original signal.
\item define virtual dampers with filter banks whose cutoff frequencies and/or bandwidths are dynamically controlled through envelope following.
\item using the signal of an acoustic instrument exclusively as a controller of synthesis sounds in a live set (no original signal in out).
\end{itemize}

\subsection{Pitch follower}\label{pitch-follower}

Pitch following is generally less stable and precise than envelope following.

Usually it returns two parameters:

\begin{itemize}
\tightlist
\item estimated pitch.
\item founded or not founded pitch (few times accuracy percentage).
\end{itemize}

There are two main techniques:
\begin{itemize}
\tightlist
\item autocorrelation \(\rightarrow\) \textit{Pitch} UGens.
\item FFT \(\rightarrow\) \textit{Tartini} UGens (SuperCollider extension).
\end{itemize}

First is cpu cheaper.

To improve accuracy we add an envelope follower: if the amplitude of the analyzed signal is less than a threshold it is not resynthesized.

\begin{lstlisting}[frame=single, caption=Pitch follower models] 
// continuos autocorrelation
SynthDef(\pfol1, {arg busIn=0,busOut=0,high=1000,low=60,median=1,
                      atk=0.01, dec=0.01, filt=1000;
                  var sig, amp, freq, hasFreq;
                      sig = In.ar(busIn,1);
                      amp = Amplitude.kr(sig, atk, 0.01);
                      sig = LPF.ar(sig, filt);
                      // two variables (Python like syntax)
                      #freq, hasFreq = Pitch.kr(sig,
                                                high,    // reference pitch
                                                low,     // lowest pitch
                                                high,    // hightest pitch
                                                median:median, // Median filter
                                                );
                      freq.poll;
                      hasFreq.poll;
                  Out.kr(busOut,[freq, hasFreq, amp])  // three channels bus
                  }).add;
// continuos FFT
SynthDef(\pfol2, {arg busIn=0,busOut=0,atk=0.01,dec=0.01,filt=2000;
                  var sig, amp, freq, hasFreq;
                      sig = In.ar(busIn,1);
                      amp = Amplitude.kr(sig, atk, 0.01); // Amplitude follower
                      sig = LPF.ar(sig, filt);            // Low pass filter
                      #freq, hasFreq = Tartini.kr(sig);   // Pitch follower
                      freq.poll;
                      hasFreq.poll;
                  Out.kr(busOut,[freq, hasFreq, amp])      // 3 canali...
                  }).add;
// trigger
SynthDef(\pfol3, {arg busIn=0, busOut=0, low=200, high=300, filt=2000;
                  var sig, freq, hasFreq,trig1,trig2,trig;
                      sig = In.ar(busIn, 1);
                      sig = LPF.ar(sig, filt);
                      #freq, hasFreq = Tartini.kr(sig);
                      freq.poll;
                      trig1 = freq > low;
                      trig2 = freq < high;
                      // limits redundancies
                      trig  = Trig1.ar((trig1 + trig2 -1).poll, 0.5); 
                  Out.kr(busOut,[freq, hasFreq]);

		// Server --> Interpreter
		
		          SendTrig.ar(trig,
		                      113,
		                      freq)
		          }).add;
\end{lstlisting} 

Continuos mapping example.

Try pfol1 and pfol2 to compare results.

\begin{lstlisting}[frame=single] 
SynthDef(\sine1, {arg busIn=0, busOut=0, thresh=0.05, pan=0;
                  var sig, ksig, env;
                      ksig = In.kr(busIn, 3);
                      sig  = Mix(SinOsc.ar(ksig[0] * [0.5,1,3])); // three oct
                      // if amp > thresh = 1
                      env  = (ksig[2] > thresh).lag(0.4) * 0.2;
                      sig  = sig * env * ksig[1];
                      sig = Pan2.ar(sig, pan);
                  Out.ar(busOut, sig)
	              }).add;

~featureBusIn  = Bus.audio(s, 1);  // Bus signal In
~featureBusOut = Bus.control(s, 3); // Bus featured control values 3 channels

~source = Synth(\mic, [\busIn,0, \busOut, ~featureBusIn, \amp,1], ~micGrp); 
~pchf   = Synth(\pfol1, [\busIn,~featureBusIn, // Try to change with pfol1
                         \busOut,~featureBusOut,
                         \median,7], ~featGrp);
~player = Synth(\sine1, [\busIn, ~featureBusOut, 
                         \busOut,0], ~playGrp);

s.defaultGroup.deepFree; 
\end{lstlisting} 

Trigger mapping example.

If an estimated pitch is in a range \(\rightarrow\) trig.

\begin{lstlisting}[frame=single] 
SynthDef(\sine2, {arg freq;
                  var sig, env;
                      sig  = Mix(SinOsc.ar(freq * [0.5,2,3])); // three oct
                      env  = EnvGen.kr(Env.perc, doneAction:2);
                  Out.ar(0, sig * env * 0.2!2)
                  }).add;

~featureBusIn  = Bus.audio(s, 1);   // Bus signal In
~featureBusOut = Bus.control(s, 3); // Bus featured control values 3 channels

~source = Synth(\mic, [\busIn,0, \busOut, ~featureBusIn, \amp,1], ~micGrp); 
~pchf   = Synth(\pfol3, [\busIn,~featureBusIn,     // Pitch UGen
                         \busOut,~featureBusOut,
                         \median,7], ~featGrp);
~player = OSCFunc.new({arg msg; msg.postln; 
                       Synth(\sine2, [\freq, msg[3]], ~playGrp)},
                       '/tr', s.addr);

s.defaultGroup.deepFree; 
\end{lstlisting} 

Few ideas:

\begin{itemize}
\tightlist
\item trig selected pitched soundfiles (pitch choose which file to play).
\item control pitch of a frequency shifter 
\item control a modular oscillator frequency (Ring, AM, FM).
\end{itemize}

\subsection{Onset detection}\label{onset-detection}

The main technique consists in comparing a signal with a copy of itself.

In SuperCollider we can use the Slope UGen.

\begin{lstlisting}[frame=single, caption=Onset detection model] 
SynthDef(\onsDec, {arg busIn=0, busOut=0,
                       atk=0.01, dec=0.01, dur=0.2, thresh=12;
                   var sig, amp, slope, trig;
                       sig   = In.ar(busIn,1);
                       amp   = Amplitude.ar(sig,atk,dec); // Env follower
                       slope = Slope.ar(amp);
                       trig  = Trig1.ar(slope > thresh, dur);
                   Out.ar(busOut, trig);

		// Server --> Interpretere
		           SendTrig.ar(trig,153, 1)
		           }).add;
\end{lstlisting} 

An example with threshold.

\begin{lstlisting}[frame=single] 
SynthDef(\saw, {arg busIn=0,busOut=0,pan=0;
                var sig, gate, env;
                    gate = In.ar(busIn,1);
                    env  = Env.adsr;
                    env  = EnvGen.kr(env, gate); // receive from detect
                    sig  = Saw.ar(LFNoise0.kr([10,12]).range(300,1000));
                    sig  = sig * env * 0.5;
                    sig  = Pan2.ar(sig, pan);
                Out.ar(busOut,sig * env * 0.5)
                }).add;
SynthDef(\noise, {arg busOut=0,pan=0;
                  var sig, env;
                      sig  = PinkNoise.ar;
                      env  = Env.perc(0.01,TRand.kr(0.02,0.1,1));
                      env  = EnvGen.kr(env, 1, doneAction:2);
                      sig  = sig * env;
                      sig  = Pan2.ar(sig, pan);
                  Out.ar(busOut, sig)
                  }).add;

~featureBusIn  = Bus.audio(s, 1);  // Bus signal In
~featureBusOut = Bus.audio(s, 1);  // Bus featured values 

~source = Synth(\mic, [\busIn,0, \busOut, ~featureBusIn, \amp,1], ~micGrp); 
~detect = Synth(\onsDec, [\busIn,~featureBusIn,    
                         \busOut,~featureBusOut,
                         \thresh, 12], ~featGrp);
~player = Synth(\saw, [\busIn, ~featureBusOut, 
                       \busOut,0], ~playGrp);
~noise  = OSCFunc.new({arg msg; 
                       Synth(\noise,target:~playGrp)},
                       '/tr', s.addr);

s.defaultGroup.deepFree; 
\end{lstlisting} 

More about onset detection and beat tracking see these UGens help files:
\begin{itemize}
\tightlist
\item \href{https://doc.sccode.org/Classes/Onsets.html}{Onsets} (FFT).
\item \href{https://doc.sccode.org/Classes/BeatTrack.html}{BeatTrack} (FFT).
\item \href{https://doc.sccode.org/Classes/Coyote.html}{Coyote} (Extension non FFT).
\end{itemize}

\subsection{Spectral features}\label{spectral-features}

There are many FFT analyses that can be used for feature extraction.

As example here:
\begin{itemize}
\tightlist
\item spectral centroid \(\rightarrow\)  useful indicator of the perceptual brightness of a signal.
\item spectral flatness \(\rightarrow\) from approx 0 for a pure sinusoid, to approx 1 for white noise.
\end{itemize}

The syntax is similar for all.

\begin{lstlisting}[frame=single, caption=Spectral features model] 
s.freqscope;

SynthDef(\scentr, {arg busIn=0, busOut=0;
                   var sig, chain;
                       sig   = In.ar(busIn, 1);
                       chain = FFT(LocalBuf(2048), sig);
                       sig   = SpecCentroid.kr(chain);
                       sig.poll(10);
                   Out.kr(busOut, sig); // control rate
                   }).add;

SynthDef(\sflat, {arg busIn=0, busOut=0;
                  var sig, chain;
                      sig   = In.ar(busIn, 1);
                      chain = FFT(LocalBuf(2048), sig)
                      sig   = SpecFlatness.kr(chain);
                      sig.poll(10);
                  Out.kr(busOut, sig); // control rate
                  }).add;
\end{lstlisting} 

Spectral centroid exemple.

\begin{lstlisting}[frame=single] 
SynthDef(\fnoise, {arg busIn=0, busOut=0, freq=0, pan=0, gate=0, bw=0.2;
	               var sig, amp, env;
	                   sig = Saw.ar(100);
	                   amp = In.ar(busIn,1);
				  	   amp = Amplitude.ar(amp);       // Env follower
	                   sig = Resonz.ar(sig, freq.lag(0.5), bw.lag(0.5));
	                   env = Linen.kr(gate, doneAction:2);
	                   sig = sig * env * amp * 4;
	                   sig = Pan2.ar(sig, pan);
	               Out.ar(busOut, sig); 
         }).add;

~featureBusIn  = Bus.audio(s, 1);   // Bus signal In
~featureBusOut = Bus.control(s, 1); // Bus featured control values 

~source = Synth(\mic, [\busIn,0, \busOut, ~featureBusIn, \amp,1], ~micGrp); 
~ksig   = Synth(\scentr, [\busIn,~featureBusIn,    
                          \busOut,~featureBusOut], ~featGrp);
~player = Synth(\fnoise, [\busIn, ~featureBusIn,
	                      \busOut,0,
		                  \freq, ~featureBusOut.asMap,
		                  \gate, 1], ~playGrp);
s.defaultGroup.deepFree; 
\end{lstlisting} 

Spectral flattness example.

\begin{lstlisting}[frame=single] 
~featureBusIn  = Bus.audio(s, 1);   // Bus signal In
~featureBusOut = Bus.control(s, 1); // Bus featured control values 

~source = Synth(\mic, [\busIn,0, \busOut, ~featureBusIn, \amp,1], ~micGrp); 
~ksig   = Synth(\sflat, [\busIn,~featureBusIn,    
                         \busOut,~featureBusOut], ~featGrp);
~player = Synth(\fnoise, [\busIn, ~featureBusIn,
	                      \busOut,0,
						  \freq, 2800,
		                  \bw, ~featureBusOut.asMap,
		                  \gate, 1], ~playGrp);
s.freeAll;
\end{lstlisting} 

\section{Classic live electronics sound processing}\label{classic-live-electronics-sound-processing}

In this section we find the main techniques historically used in pieces for instruments and live processing.

They are all almost all based on the real-time recording of one or more buffers whose contents are playbacked according to different techniques.

\begin{center}
\includegraphics[scale=0.6]{RecBuf_1.png}
\end{center}

Let's build the environment.

\begin{lstlisting}[frame=single] 
s.waitForBoot{
~micGrp = Group.new;            // sources Group
~recGrp = Group.after(~micGrp); // recorder and ksig Group
~fxGrp  = Group.after(~recGrp); // fx Group
s.sync;
SynthDef(\mic, {arg busIn=0, busOut=0, amp=0;
                    var sig;
                    sig = SoundIn.ar(busIn) * amp.lag;
                    sig = LeakDC.ar(sig);
                Out.ar(busOut,sig)
                }).add;           
SynthDef(\ksig,{arg type=0, range=#[0,1], freq=1, busOut=0;
	            var sig;
	                sig = Select.kr(type,
                                [MouseX.kr(range[0], range[1]), // 0
                                 MouseY.kr(range[0], range[1]), // 1
                                 LFNoise1.kr(freq).range(range[0], range[1]), // 2
                                 LFSaw.kr(freq).range(range[0], range[1]),    // 3
                                 Impulse.kr(freq),              // 4
                                 Dust.kr(freq),                 // 5
                                ]);
	            Out.kr(busOut,sig)
                }).add;
s.sync;
s.meter;
s.plotTree;
};
\end{lstlisting} 

Define a Synth for recording.

\begin{lstlisting}[frame=single, caption=Live recording model] 
SynthDef(\rec,{arg buf=0, busIn=0, loop=0, mix=0, done=2;
               var in;
                   in = In.ar(busIn, 1);
                   RecordBuf.ar(in,            
                                buf,           
                                preLevel:mix,  // 1 = add audio 
                                               // 0 = clear before
                                loop:loop,     // 1 = loop
                                doneAction:done)
               }).add;
\end{lstlisting} 

Create an empty Buffer mono (set duration in frames)

In live electronics there are two ways to record it:
\begin{itemize}
\tightlist
\item one shot \(\rightarrow\) fill the Buffer until the end (or a stop message) then stop the recording.
\item loop \(\rightarrow\)  when the buffer is full it starts over from the beginning in a loop.
\end{itemize}

In both cases we can choose whether to overwrite the contents of the Buffer or delete it dynamically.

One shot example.

\begin{lstlisting}[frame=single] 
Buffer.freeAll; 
~bufDur = 3;     // buffer size in seconds
~bufLive = Buffer.alloc(s, s.sampleRate * ~bufDur, 1 );

~source   = Synth(\mic, [\busIn,0, \busOut, ~bufBusIn, \amp,1], ~micGrp); 
~recorder = Synth(\rec, [\buf, ~bufLive,
                         \busIn, ~bufBusIn,
                         \mix, 0,    // no overwriting 
                         \loop, 0,   // no loop
                         \done, 2], ~recGrp); 
                         
~bufLive.play;           // monitoring not playback
s.defaultGroup.deepFree; // clear Synths, not Groups
\end{lstlisting} 

Loop exemple.

\begin{lstlisting}[frame=single] 
Buffer.freeAll; 
~bufDur = 3;     // buffer size in seconds
~bufLive = Buffer.alloc(s, s.sampleRate * ~bufDur, 1 );

~source   = Synth(\mic, [\busIn,0, \busOut, ~bufBusIn, \amp,1], ~micGrp); 
~recorder = Synth(\rec, [\buf,~bufLive,
                         \busIn,~bufBusIn,
                         \mix,0,    // clear before
                         \loop,1,   // no loop
                         \done,2], ~recGrp); 
                         
~bufLive.play; 
s.defaultGroup.deepFree; 
\end{lstlisting} 

\subsection{Ring modulation and frequency shifting}\label{ring-modulation-and frequency-shifting}

An input signal is multiplied by a sinusoid (both signals are bipolar).

Output signal consisting of the sum and difference of their original partial (known as sidebands) while eliminating the original input signals.

This process usually generates inharmonic, metallic, bell-like sounds or robotic voices.

One of the earliest musical instruments utilizing a ring modulator was the Melochord (1947) built by Harald Bode.

Karlheinz Stockhausen used for the first time ring modulation in 1956 for some sounds in \href{http://www.musicaecodice.it/gitmedia/emc/7_media/gesange.mp3}{Gesang der Jünglinge} - extract.

The distinctive voice of the \href{http://www.musicaecodice.it/gitmedia/emc/7_media/dalek.mp3}{Daleks} in the television series Doctor Who starting in 1963 is produced by ring modulation.

John McLaughlin employs the ring modulator heavily in the 1974 Mahavishnu Orchestra album Visions of the Emerald Beyond, especially on the track \href{http://www.musicaecodice.it/gitmedia/emc/7_media/mala.mp3}{On the Way Home to Earth} - extract.

The Synth model.

\begin{lstlisting}[frame=single, caption=Live ring modulation model] 
SynthDef(\ring, {arg busIn=0, busOut=0, fmod=400, idx=0, amp=0, gate=0, pan=0;
                 var car, mod, env, sig;
                     car = In.ar(busIn, 1);
                     mod = SinOsc.ar(fmod) * idx;
                     env = Linen.kr(gate, doneAction:2);
                     sig = car * mod * amp * env;
                     sig = Pan2.ar(sig, pan);
                 Out.ar(busOut, sig)
                 }).add;
\end{lstlisting} 

In this example we dynamically control the modulation index and the frequency of the modulating oscillator with the mouse.

\begin{lstlisting}[frame=single] 
~xbus = Bus.control(s,1);
~ybus = Bus.control(s,1);

~fxBusIn  = Bus.audio(s, 1);  // Bus fx in 

~source = Synth(\mic,   [\busIn,0, \busOut, ~fxBusIn, \amp,1], ~micGrp); 
~mousex = Synth(\ksig,  [\type, 0, \range, [300, 1300], \busOut, ~xbus], ~recGrp); 
~mousey = Synth(\ksig,  [\type, 0, \range, [0, 1],      \busOut, ~ybus], ~recGrp); 

~ring   = Synth(\ring, [\busIn, ~fxBusIn,
                        \busOut, 0,
                        \idx,  ~ybus.asMap, // mouse y 
                        \fmod, ~xbus.asMap, // mouse x 
                        \amp, 1,
                        \gate, 1], ~fxGrp); 
s.defaultGroup.deepFree; 
\end{lstlisting} 

As an example of augmented instrumental techniques we can:
\begin{itemize}
\tightlist
\item map envelope follower \(\rightarrow\) modulation index (louder more modulated or vice versa).
\item map spectral centroid \(\rightarrow\) modulation frequency.
\end{itemize}

Added also a chorusing to modulation frequency.

\begin{lstlisting}[frame=single] 
SynthDef(\ring1, {arg busIn=0, busOut=0, amp=0, gate=0, pan=0;
                  var car, mod, chain, fmod, idx, env, sig;
                      car = In.ar(busIn, 1);
                      idx = Amplitude.ar(car).lag(0.5); // amp follower
                      chain = FFT(LocalBuf(2048), car);
                      fmod  = SpecCentroid.kr(chain).lag(0.5);   // centroid
                      mod = Mix(SinOsc.ar([fmod,fmod+0.5])) * idx; // chorus
                      env = Linen.kr(gate, doneAction:2);
                      sig = car * mod * amp * env;
                      sig = Pan2.ar(sig, pan);
                  Out.ar(busOut, sig)
                  }).add;

~fxBusIn  = Bus.audio(s, 1);  // Bus fx in 

~source = Synth(\mic,   [\busIn,0, \busOut, ~fxBusIn, \amp,1], ~micGrp); 
~ring   = Synth(\ring1, [\busIn, ~fxBusIn,
                         \busOut, 0,
                         \amp, 1,
                         \gate, 1], ~fxGrp); 
s.defaultGroup.deepFree; 
\end{lstlisting} 

Ring modulation is a special case of AM and frequency shifting is a special case of AM.

Single-sideband AM shifts all partials by a constant amount but does not preserve the original frequency relationships.

In SuperCollider we can use th FreqShift UGen.

\begin{lstlisting}[frame=single, caption=Live frequency shifter model] 
SynthDef(\fshift, {arg busIn=0, busOut=0, fshift=0, 
                       amp=0, pan=0, mix=0, gate=0;
                   var sIn, sig, env;
                       sIn = In.ar(busIn, 1);
                       sig = FreqShift.ar(sIn, fshift);
                       sig = XFade2.ar(sIn, sig, mix);
                       env = Linen.kr(gate, doneAction:2);
                       sig = sig * env * amp;
                       sig  = Pan2.ar(sig, pan);
                   Out.ar(busOut, sig)
                   }).add;
\end{lstlisting} 

Mouse x \(\rightarrow\) mix between original and shofted sound.

Mouse y \(\rightarrow\) freq shift range (here 0-500 Hz) 

\begin{lstlisting}[frame=single] 
~xbus = Bus.control(s,1);
~ybus = Bus.control(s,1);

~fxBusIn  = Bus.audio(s, 1);  // Bus fx in 

~source = Synth(\mic,   [\busIn,0, \busOut, ~fxBusIn, \amp,1], ~micGrp); 
~mousex = Synth(\ksig,  [\type, 0, \range, [0, 1], \busOut, ~xbus], ~recGrp); 
~mousey = Synth(\ksig,  [\type, 0, \range, [0, 500],      \busOut, ~ybus], ~recGrp); 

~ring   = Synth(\fshift, [\busIn, ~fxBusIn,
                          \busOut, 0,
                          \fshift,  ~ybus.asMap, // mouse y 
                          \mix,     ~xbus.asMap, // mouse x 
                          \amp, 1,
                          \gate, 1], ~fxGrp);
s.defaultGroup.deepFree; 
\end{lstlisting} 

\subsection{Live recording and playback}\label{live-recording-and-playback}

During a performance we can record some parts played live in one or more buffers and then process them with the techniques illustrated in the dedicated paragraph of chapter 3 (\ref{sound-processing-techniques-in-supercollider}).

Remember that there are two oscillator types:
\begin{itemize}
\tightlist
\item sample playback oscillator (\textit{PlayBuf}).
\item buffer reading oscillator (\textit{bufRd}).
\end{itemize}

\begin{lstlisting}[frame=single] 
SynthDef(\plbk, {arg buf=0, busOut=0, pos=0, dur=0.2, amp=0,
                     trsp=0, dir=1, pan=0, t_gate=0, done=2;
                 var sig, env;
                     sig = PlayBuf.ar(1, buf,
                                      BufRateScale.kr(buf) * trsp.midiratio 
                                                           * dir,           
                                      t_gate,                               
                                      BufSampleRate.kr(buf)* pos            
	                                  );
                     env = Env.linen(0.01,dur-0.02,0.01);                   
                     env = EnvGen.kr(env, t_gate, doneAction:done);
                     sig = sig * env * amp;
                     sig = Pan2.ar(sig);
                 Out.ar(busOut, sig)
                 }).add;

SynthDef(\sch, {arg buf=0, busOut=0, smooth=0.02, amp=0, pos=0, pan=0;
                var pnt, sig;
                    pnt = Lag.kr(pos.linlin(0,1,0,BufFrames.kr(buf)),smooth);
                    sig = BufRd.ar(1, buf, K2A.ar(pnt));
                    sig = Pan2.ar(sig * amp, pan);
                Out.ar(busOut, sig)
                }).add;
\end{lstlisting} 

\subsubsection{Asynchronous}\label{asynchronous}

We can:

\begin{itemize}
\tightlist
\item record live sources in one or more Buffers.
\item play it back with:
    \begin{itemize}
    \tightlist
    \item  simple playback (transposition, direction, cutting, etc.)
    \item windowing, enveloping, looping or slicing sequences (both deterministic and non-deterministic), 
    \item scratching machines.
    \end{itemize}
\end{itemize}

A simple slicing example controlled by computer keys.

\begin{itemize}
\tightlist
\item \textit{r} trig the buffer recording.
\item \textit{p} trig the processing.
\item \textit{s} stop the porcessing.
\end{itemize}

\begin{lstlisting}[frame=single] 
Buffer.freeAll; 
~bufDur  = 3;     // buffer size in seconds
~bufLive = Buffer.alloc(s, s.sampleRate * ~bufDur, 1 );

~bufBusIn = Bus.audio(s, 1);  // Bus to buffer

~source   = Synth(\mic, [\busIn,0, \busOut, ~bufBusIn, \amp,1], ~micGrp); 

// triggers from keyboard
w = Window.new("key");
w.front;
w.view.keyDownAction_({arg ...args;
	                        switch(args[1],             
		                            $r, {Synth(\rec, [\buf, ~bufLive,
                                                              \busIn, ~bufBusIn,
                                                              \mix, 0,    
                                                              \loop, 0], ~recGrp)},
                                    $p, {r.reset.play},
                                    $s, {r.stop}) 
                       });
r = Routine.new({
                 inf.do({
                         Synth(\plbk, [\buf, ~bufLive,
                                       \out, rand(2),
                                       \pos, rand(~bufLive.duration)-0.3, 
                                       \dur, rrand(0.05,0.3),
                                       \amp, rand(1.0),
                                       \trsp, rand2(5),
                                       \dir, [1,-1].choose,
                                       \pan, rand2(1.0),
                                       \t_gate, 1
                                       ], ~fxGrp);
                         rrand(0.05,0.3).wait
	                     })
                });
s.defaultGroup.deepFree;   w.close.free;
\end{lstlisting} 

A scratching machine controlled by mouse x position.

\begin{lstlisting}[frame=single] 
Buffer.freeAll; 
~bufDur   = 3;     // buffer size in seconds
~bufLive  = Buffer.alloc(s, s.sampleRate * ~bufDur, 1 );
~bufBusIn = Bus.audio(s, 1);  // Bus to buffer

~xbus     = Bus.control(s,1); // scratch values

~source = Synth(\mic,   [\busIn,0, \busOut, ~bufBusIn, \amp,1], ~micGrp); 
~mousex = Synth(\ksig,  [\type, 0, \range, [0, 1], \busOut, ~xbus], ~recGrp); 

// triggers from keyboard
w = Window.new("key");
w.front;
w.view.keyDownAction_({arg ...args;
	                        switch(args[1],             
		                        $r, {Synth(\rec, [\buf, ~bufLive,
                                                  \busIn, ~bufBusIn,
                                                  \mix, 0,    
                                                  \loop, 0], ~recGrp)},
                                $p, {~str = Synth(\sch, [\buf, ~bufLive,
                                                         \busOut, 0,
                                                         \amp, 1,  
                                                         \pos, ~xbus.asMap,
                                                         \smooth, 0.2], ~fxGrp)},
                                $s, {~str.free}) 
                       });
s.defaultGroup.deepFree;  w.close.free;
\end{lstlisting} 

Let's remember that as position (normalized between 0 and 1) we can use any type of control signal whether coming from external devices (MIDI, OSC, etc.) or from internal oscillators or from feature extractions.

\subsubsection{Loop station}\label{loop-station}
The processes illustrated in the previous paragraph are asynchronous.

Here we design a loop station that playback to a regular pulse and its subdivisions.

Let's define a \textit{metronome} synth that:

\begin{itemize}
\tightlist
\item generates beats in bpm
\item calculates the delta time between them.
\end{itemize}

It writes the values on two buses.

We then define a player that accepts the synchronized trigger and the delta time as input, with the ability to define beat subdivisions.

This way all players will be synchronized to the same external metronome.

\begin{lstlisting}[frame=single, caption=Live looping machine model] 
SynthDef(\metro, {arg bpm=60, busTrig=99, busDur=100;
                  var bps, sec, sig;
                      bps = bpm/60*100;  // bpm to Hz / 100 parts
                      sig = Impulse.ar(bps);
                      sec = 60/bpm;      // Delta in seconds (duration)
                  Out.ar(busTrig,sig);   // Trigger on audio Bus
                  Out.kr(busDur,sec);    // Duration on contro Bus
                  }).add;
SynthDef(\loop, {arg buf=0, busTrig=99, busDur=100, busOut=0,
                     pos=0, sudd=1, legato=0, amp=0,
                     dir=1, gate=0, pan=0, done=2;
                 var dur, trig, sig, env, fade;
                     dur  = In.kr(busDur) * (1/sudd);       // scaled
                     trig = PulseDivider.ar(In.ar(busTrig), 100/sudd); 
                     sig  = PlayBuf.ar(1, buf,
                                       BufRateScale.kr(buf) * dir,
                                       trig,      // external trigger
                                       BufFrames.kr(buf) * pos);
                     env  = Env.linen(0.01,(dur * legato)-0.02,0.01);  
                     env  = EnvGen.ar(env, trig); // external trigger
                     fade = Linen.kr(gate, doneAction:done);
                     sig  = sig * fade * env * amp;
                     sig  = Pan2.ar(sig, pan);
                 Out.ar(busOut, sig)
                 }).add;
\end{lstlisting} 

Let's assemble everything and record the Buffer.

\begin{lstlisting}[frame=single] 
~bpm     = 60;
~dur     = 3;

Buffer.freeAll;
~bufLive  = Buffer.alloc(s, s.sampleRate * ~dur);
~bufBusIn = Bus.audio(s, 1);  // Bus to buffer

~trigBus = Bus.audio(s);      // Bus Trigger (loopers)
~durBus  = Bus.control(s);    // Bus delta (loopers)

~source = Synth(\mic,   [\busIn,0, \busOut, ~bufBusIn, \amp,1], ~micGrp); 
~pulse  = Synth(\metro, [\bpm,  ~bpm,  \busTrig, ~trigBus, \busDur, ~durBus], ~recGrp);

// triggers from keyboard
w = Window.new("key");
w.front;
w.view.keyDownAction_({arg ...args;
	                       if(args[1]==$r)             
		                   {Synth(\rec, [\buf, ~bufLive,
                                         \busIn, ~bufBusIn,
                                         \mix, 0,    
                                         \loop, 0], ~recGrp)}
                       });
\end{lstlisting} 

Play it.

\begin{lstlisting}[frame=single] 
~loop1  = Synth(\loop,  [\buf,  ~bufLive,
                         \busTrig, ~trigBus,
                         \busDur,  ~durBus,
                         \busOut, 0,
                         \pos, 0,   // 0-1
                         \sudd, 1,
                         \legato,1, // 0-1
                         \amp, 1,
                         \dir, 1,
                         \gate, 1], ~fxGrp);
	                     
~loop1.set(\pos, 0.1); // change parameters
~loop1.set(\legato, 0.7);
~loop1.set(\sudd, 2);
~loop1.set(\amp, 0.7);
\end{lstlisting} 

Let's make a second looper.

\begin{lstlisting}[frame=single] 
~loop2  = Synth(\loop,  [\buf,  ~bufLive,
                         \busTrig, ~trigBus,
                         \busDur,  ~durBus,
                         \busOut, 0,
                         \pos, 0.8,               
                         \sudd, 2,
                         \legato,0.3,             
                         \amp, 1,
                         \dir, 1,
                         \gate, 1], ~fxGrp);
	                     
~loop2.set(\pos, 0.7); // change parameters
~loop2.set(\sudd, 5);
~loop1.set(\gate, 0); ~loop2.set(\gate, 0);
s.defaultGroup.deepFree; 
\end{lstlisting} 

We can work with many buffers and many loopers recording asynchronously thus creating complex rhythmic and harmonic grids.

\subsection{Granular synthesis}\label{granular-synthesis}

We can perform live granular synthesis in two ways:
\begin{itemize}
\tightlist
\item asynchronous.
\item synchronous.
\end{itemize}

\subsubsection{Asynchronous}\label{asynchronous}

In this mode, we record the buffer in one of two possible ways (one shot or loop) and play it back with one of the synths presented in the computer music chapter (\ref{granular}).

An example.

The SynthDefs.

\begin{lstlisting}[frame=single] 
SynthDef(\grain_1,{arg busOut=0, buf=0, pos=0, trig=0,
	                   gdur=0.1, amp=0, trsp=0, pan=0, 
	                   gate=0, done=2;
	               var gfreq, sig, env;
	                   gfreq = 2.0/gdur;        // 2 overlap...
	                   pos   = pos * BufDur.kr(buf);
	                   sig   = TGrains.ar(2,    // channels 
		                                  trig, 
		                                  buf, 
		                                  trsp.midiratio, 
		                                  pos, // in seconds 
		                                  gdur, 
		                                  pan, // depends o chls number 
		                                  amp, 
		                                  4    // interpolation 1,2 4
	                                      );
		               env   = Linen.kr(gate,doneAction:done);
	                   sig   = sig * amp * env;
	               Out.ar(busOut, sig * env);
                   }).add;
\end{lstlisting} 

Indipendent recorder.

Indipendent player.

\begin{itemize}
\tightlist
\item \textit{r} trig the buffer recording.
\item \textit{p} trig the processing.
\item \textit{s} stop the processing.
\end{itemize}

\begin{lstlisting}[frame=single] 
Buffer.freeAll; 
~bufDur   = 3;     // buffer size in seconds
~bufLive  = Buffer.alloc(s, s.sampleRate * ~bufDur, 1 );
~bufBusIn = Bus.audio(s, 1);  // Bus to buffer

~kpos  = Bus.control(s, 1);
~ktrig = Bus.control(s, 1);

~source  = Synth(\mic,   [\busIn,0, \busOut, ~bufBusIn, \amp,1], ~micGrp); 

~pointer = Synth(\ksig,  [\type, 2, \freq, 2, \busOut, ~kpos], ~recGrp); 
~trigger = Synth(\ksig,  [\type, 4, \freq, 15, \busOut, ~ktrig], ~recGrp); 

// triggers from keyboard
w = Window.new("key");
w.front;
w.view.keyDownAction_({arg ...args;
	                        switch(args[1],             
		                            $r, {Synth(\rec, [\buf, ~bufLive,
                                                      \busIn, ~bufBusIn,
                                                      \mix, 0,    
                                                      \loop, 0], ~recGrp)},
                                    $p, {~gr = Synth(\grain_1, [\busOut, 0,
                                                                \buf, ~bufLive,
                                                                \pos, ~kpos.asMap,
                                                                \trig, ~ktrig.asMap,
                                                                \gdur, 0.1,
                                                                \trsp, 0,
                                                                \amp, 1,
                                                                \pan, 0,
                                                                \gate, 1], ~fxGrp);
                                    },
                                    $s, {~gr.set(\gate, 0)}) 
                       });
s.defaultGroup.deepFree; w.close.free; 
\end{lstlisting} 

\subsubsection{Synchronous (harmonizer)}\label{synchronous-harmonizer}

If we want a real live granular synthesis we must sync:
\begin{itemize}
\tightlist
\item position in buffer recording Synth.
\item position in buffer playback Synth
\end{itemize}

\begin{center}
\includegraphics[scale=0.65]{gran_17.png}
\end{center}

The sync phasor and the recorder.

\begin{lstlisting}[frame=single, caption=Live sync phasor and buffer recorder model] 
SynthDef(\pos, {arg busOut=0,buf=0,rate=1;
	            var sig;
	                sig = Phasor.ar(0, 
					                BufRateScale.kr(buf) * rate, // incremental factor
									0, BufFrames.kr(buf));       // start - end
	            Out.ar(busOut, sig);
                }).add;

SynthDef(\syncrec, {arg busIn=0, busPos=0, buf=0;
	                var ptr, sig;
	                    ptr = In.ar(busPos, 1); 
	                    sig = In.ar(busIn, 1);
	                BufWr.ar(sig, buf, ptr);  
                    }).add;

// N.B. rate=0 stop at last sample position
\end{lstlisting} 

Then we can use any granular synth from chapter 3 with few changes:
\begin{itemize}
\tightlist
\item audio bus for pointer (not normailzed) instead a control bus.
\item position signal is not normalized.
\end{itemize}

\begin{lstlisting}[frame=single] 
SynthDef(\gharm,{arg busOut=0,  busPos=0,  buf=0, trig=0,
	                 gdur=0.1, amp=0, trsp=0, pan=0,
	                 gate=0, done=2;
	            var pos, sig, env;
	                pos   = In.ar(busPos,1) / SampleRate.ir(buf);
	                sig   = TGrains.ar(2, trig, buf, trsp.midiratio, pos, gdur, pan, amp, 4);
		            env   = Linen.kr(gate,doneAction:done);
                    sig   = sig * env;
	            Out.ar(busOut, sig);
}).add;
\end{lstlisting} 

Test it.

\begin{lstlisting}[frame=single] 
Buffer.freeAll; 
~bufDur   = 3;     // buffer size in seconds
~bufLive  = Buffer.alloc(s, s.sampleRate * ~bufDur, 1 );
~bufBusIn = Bus.audio(s, 1);  // Bus to buffer

~kpos  = Bus.audio(s, 1);     // audio bus...
~ktrig = Bus.control(s, 1);

~source  = Synth(\mic,     [\busIn,0, \busOut, ~bufBusIn, \amp,1], ~micGrp); 
~pointer = Synth(\pos,     [\buf, ~bufLive, \busOut, ~kpos], ~micGrp); 
~record  = Synth(\syncrec, [\busIn,~bufBusIn, \busPos, ~kpos, \buf,~bufLive], ~recGrp); 
~trigger = Synth(\ksig,    [\type, 4, \freq, 15, \busOut, ~ktrig], ~recGrp);

~grain   = Synth(\gharm, [\busOut, 0,
                          \buf,  ~bufLive,
                          \busPos, ~kpos,
                          \trig, ~ktrig.asMap,
                          \gdur, 0.1,
                          \trsp, 4,
                          \amp,  1,
                          \pan,  0,
                          \gate, 1], ~fxGrp);
                          
~trigger.set(\freq,20);  // grain freq
~grain.set(\trsp,4);     // trasposition
(
// granulator
~trigger.set(\type,5, \freq,25); // trigger type
~grain.set(\trsp,4, \gdur, 0.1); 
)

s.defaultGroup.deepFree; 
\end{lstlisting} 

If we change the frequency of the control signal:
\begin{itemize}
\tightlist
\item freq < 20Hz \(\rightarrow\) audible grains.
\item freq  > 20Hz \(\rightarrow\) harmonizer.
\end{itemize}

If we want only an harmonizer we can use a dedicate UGens: \textit{PitchShift} that have an internal buffer.

\begin{lstlisting}[frame=single, caption=Live granular harmonizer model] 
SynthDef(\harm,{arg busIn=0, busOut=0, trsp=0, 
	                 gdur=0.1, prand=0, trand=0, amp=0, pan=0,
	                 gate=0, done=2;
	            var sig, env;
                    sig = In.ar(busIn);
	                sig = PitchShift.ar(sig,
                                        gdur,           // grin dur
                                        trsp.midiratio, // rate
                                        prand,  // pitch chorus
                                        trand); // time chorus < gdur
		            env = Linen.kr(gate,doneAction:done);
                    sig = sig * env * amp;
                    sig = Pan2.ar(sig, pan);
	            Out.ar(busOut, sig);
}).add;
\end{lstlisting} 

A chord exemple.

\begin{lstlisting}[frame=single] 
~fxBusIn = Bus.audio(s, 1);  // Bus to buffer

~chord  = [ -5,   0,   4,   7];   // major chord
~amps   = [0.1, 0.4, 0.3, 0.2];   // amps
~source = Synth(\mic,  [\busIn,0, \busOut, ~fxBusIn, \amp,1], ~micGrp); 

~harm = ~chord.collect({arg i, id;
                        Synth(\harm, [\busIn, ~fxBusIn,
                                      \busOut, 0,
                                      \gdur, 0.2,
                                      \trsp, ~chord[id],
                                      \amp,  ~amps[id],
                                      \pan,  0,
                                      \gate, 1], ~fxGrp)
                        });
                        
~harm.do({arg i; i.set(\gate, 0)}); ~source.free;
s.defaultGroup.deepFree; 
\end{lstlisting} 

\subsection{Delay lines}\label{delay-lines}

Delay lines can be used for:
\begin{itemize}
\tightlist
\item the creation of augmented instrumental gestures.
\item the generation of sonic/musical backgrounds that evolve over time.
\end{itemize}

We take care to mask or musically underline the mechanical characteristics intrinsic to this process.

There are different types of delays:
\begin{itemize}
\tightlist
\item echo.
\item feedback gain.
\item feedback duration.
\item ping pong.
\item multi tap.
\item variable time delays.
\item filtred.
\item resonator.
\end{itemize}

\subsubsection{Echo}\label{echo}

A simple delay without feedback.
\begin{itemize}
\tightlist
\item max delay \(\rightarrow\) internal buffer size.
\item delay < max delay.
\item mix \(\rightarrow\) with or without original sound.
\end{itemize}

The model.

\begin{lstlisting}[frame=single, caption=Live echo model] 
SynthDef(\echo, {arg busIn=0, busOut=0, maxdel=10, del=0.5, mix=0,
                     amp=0, gate=0, pan=0, done=2;
                 var sig, dly, env;
                     sig = In.ar(busIn);
                     dly = DelayL.ar(sig, maxdel, del);
                     dly = LeakDC.ar(dly);
                     env = Linen.kr(gate,doneAction:done);
                     sig = XFade2.ar(dly, sig, mix); // mix -1 = only dly,
                                                     // 0 = both,
                                                     // 1 = only direct sound
                                                     // float = ratio
                     sig = sig * env * amp;
                     sig = Pan2.ar(sig, pan);
                 Out.ar(busOut, sig)
                 }).add;
\end{lstlisting} 

Test it.

\begin{lstlisting}[frame=single] 
~fxBusIn = Bus.audio(s, 1); 

~source = Synth(\mic,  [\busIn,0, \busOut, ~fxBusIn, \amp,1], ~micGrp); 
~delay  = Synth(\echo, [\busIn,~fxBusIn, 
                        \busOut, 0, 
                        \maxdel, 3, 
                        \del, 1, 
                        \mix, 0, 
                        \amp,1, 
                        \gate, 1], ~fxGrp); 
                        
s.defaultGroup.deepFree; ~fxBusIn.free; ~source.free; ~delay.free;
\end{lstlisting}

\subsubsection{Feedback gain}\label{feedback-gain} 

We can add a feedback.

Duration of feedback is not directly controlled.

It depend from feedback gain (0.0 - 1.0).

The model.

\begin{lstlisting}[frame=single, caption=Live feedback gain delay model] 
SynthDef(\del_1, {arg busIn=0, busOut=0, maxdel=10, del=0.5, fbk=0.0, mix=0,
                      amp=0, gate=0, pan=0, done=2;
                  var in, local, sig, dly, env;
                      in    = In.ar(busIn);
                      local = LocalIn.ar(1);   // feedback internal bus
                      sig   = in + local;
                      dly   = DelayL.ar(sig, maxdel, del);
                      dly   = LeakDC.ar(dly);  // long feedback
                  LocalOut.ar(dly * fbk);      // feedback internal bus
                      env   = Linen.kr(gate,doneAction:done);
                      sig   = XFade2.ar(dly, sig, mix) * env * amp; 
                      sig  = Pan2.ar(sig, pan);
                  Out.ar(busOut, sig)
                  }).add;
\end{lstlisting} 

Test it.

\begin{lstlisting}[frame=single] 
~fxBusIn = Bus.audio(s, 1); 

~source = Synth(\mic,  [\busIn,0, \busOut, ~fxBusIn, \amp,1], ~micGrp); 
~delay  = Synth(\del_1, [\busIn,~fxBusIn, 
                         \busOut, 0, 
                         \maxdel, 3, 
                         \del, 1, 
                         \fbk, 0.5,
                         \mix, 0, 
                         \amp,1, 
                         \gate, 1], ~fxGrp); 
                         
s.defaultGroup.deepFree; ~fxBusIn.free; ~source.free; ~delay.free;
\end{lstlisting}

\subsubsection{Feedback duration}\label{feedback-duration} 

If we want to control the duration of the feedback in seconds (decayT) we can use the \textit{CombL} UGen.

The model.

\begin{lstlisting}[frame=single, caption=Live feedback duration delay model] 
SynthDef(\del_2, {arg busIn=0, busOut=0, maxdel=10, del=0.5, decayT=1, mix=0,
                      amp=0, gate=0, pan=0, done=2;
                  var in, sig, dly, env;
                      in  = In.ar(busIn);
                      dly = CombL.ar(in, maxdel, del, decayT);
                      env = Linen.kr(gate,doneAction:done);
                      sig = LeakDC.ar(dly);    // long feedbacks
                      sig = XFade2.ar(dly, in, mix);
                      sig = sig * env * amp;
                      sig = Pan2.ar(sig, pan);
                  Out.ar(busOut, sig)
                  }).add;
\end{lstlisting} 

Test it.

\begin{lstlisting}[frame=single] 
~fxBusIn = Bus.audio(s, 1); 

~source = Synth(\mic,  [\busIn,0, \busOut, ~fxBusIn, \amp,1], ~micGrp); 
~delay  = Synth(\del_2, [\busIn,~fxBusIn, 
                         \busOut, 0, 
                         \maxdel, 3, 
                         \del, 0.25, 
                         \decayT, 3,
                         \mix, 0, 
                         \amp,1, 
                         \gate, 1], ~fxGrp);  
                         
s.defaultGroup.deepFree; ~fxBusIn.free; ~source.free; ~delay.free;
\end{lstlisting}

\subsubsection{Ping pong}\label{ping-pong} 

A delay line with alternate panning.

The model.

\begin{lstlisting}[frame=single, caption=Live ping-pong delay model] 
SynthDef(\pingpong, {arg busIn=0, busOut=0, maxdel=2, del=0.5, fbk=0.0,
                         amp=0, gate=0, done=2;
                     var in, local, sig, dly, env;
                         in    = In.ar(busIn);
                         local = LocalIn.ar(2) + [in, 0];
                         dly   = DelayL.ar(local, maxdel, del, 1);
                         dly   = LeakDC.ar(dly);
                         env   = Linen.kr(gate,doneAction:done);
                     LocalOut.ar(dly.reverse * fbk); // reverse = ping pong effect
                     Out.ar(busOut, local * env * amp)
                     }).add;
\end{lstlisting} 

Test it.

\begin{lstlisting}[frame=single] 
~fxBusIn = Bus.audio(s, 1); 

~source = Synth(\mic,  [\busIn,0, \busOut, ~fxBusIn, \amp,1], ~micGrp); 
~delay  = Synth(\pingpong, [\busIn,~fxBusIn, 
                            \busOut, 0, 
                            \maxdel, 3, 
                            \del, 0.25, 
                            \fbk, 0.5,
                            \mix, 0, 
                            \amp,1, 
                            \gate, 1], ~fxGrp); 
                         
s.defaultGroup.deepFree; ~fxBusIn.free; ~source.free; ~delay.free;
\end{lstlisting}

\subsubsection{Multi Tap}\label{multi-tap} 

Delay lines with different times and amplitudes.

The model.

\begin{lstlisting}[frame=single, caption=Live multi tap delay model] 
SynthDef(\multitap, {arg busIn=0,busOut=0,buf=0,
                         times=#[0.1,0.5,1.2,0.8], // delay times
                         amps =#[1,  0.5,0.8,0.3], // delay amps
                         mix= 0,
                         amp=0,pan=0,gate=0,done=2;
                     var in, env, del, sig;
                         in  = In.ar(busIn);
                         env = Linen.kr(gate,doneAction:done);
                         del = MultiTap.ar(`times, `amps, in,bufnum:buf);
                         sig = XFade2.ar(del, in, mix);
                         sig = sig * amp * env;
                         sig = Pan2.ar(sig, pan);
                     Out.ar(busOut, sig)
                     }).add;
\end{lstlisting} 

Test it.

\begin{lstlisting}[frame=single] 
~fxBusIn = Bus.audio(s, 1); 

b = Buffer.alloc(s, s.sampleRate * 4, 1); // a Buffer

~source = Synth(\mic, [\busIn,0, \busOut, ~fxBusIn, \amp,1], ~micGrp); 
~delay  = Synth(\multitap, [\busIn,~fxBusIn, 
                            \busOut, 0, 
                            \buf, b,
                            \times, [0.1,0.3,0.6,1.2],  
                            \amps,   [1,  0.5,0.8,0.3], 
                            \amp,1, 
                            \gate, 1], ~fxGrp); 
                         
s.defaultGroup.deepFree; ~fxBusIn.free; ~source.free; ~delay.free; b.free;
\end{lstlisting}

\subsubsection{Variable time}\label{variable-time} 

If we use a continuous control signal that modulates the delay time we obtain transpositions and strange glitches.

The model.

\begin{lstlisting}[frame=single, caption=Live variable time delay model] 
SynthDef(\vardel, {arg busIn=0, busOut=0,
                       maxdel=10, rate=3, decayT=1, 
                       mix=0, delMin=0.1,delMax=0.4,
                       amp=0, gate=0, pan=0, done=2;
                   var in, sig, ksig, dly, env;
                       in  = In.ar(busIn);
                       ksig = LFNoise2.kr(rate)
                                      .exprange(delMin,delMax); // ksig
                       dly = CombL.ar(in, maxdel, ksig, decayT);
                       env = Linen.kr(gate,doneAction:done);
                       sig = LeakDC.ar(dly);    // Per fbk lunghi
                       sig = XFade2.ar(dly, in, mix) * env * amp;
                       sig = Pan2.ar(sig, pan);
                   Out.ar(busOut, sig)
                   }).add;
\end{lstlisting} 

Test it.

\begin{lstlisting}[frame=single] 
~fxBusIn = Bus.audio(s, 1); 

~source = Synth(\mic,  [\busIn,0, \busOut, ~fxBusIn, \amp,1], ~micGrp); 
~delay  = Synth(\vardel, [\busIn,~fxBusIn, 
                        \busOut, 0, 
                        \maxdel, 4,
                        \rate, 5, // try change it
                        \decayT, 4,  
                        \delMin,  0.1,
                        \delMax, 0.3, 
                        \amp,1, 
                        \gate, 1], ~fxGrp); 
                         
s.defaultGroup.deepFree; ~fxBusIn.free; ~source.free; ~delay.free;
\end{lstlisting}

\subsubsection{Filtred}\label{filtred} 

We can filter the delayed sound to partially mask the mechanical nature of the feedback making the sound gesture more natural.

OnePole filter:
\begin{itemize}
\tightlist
\item coeff -0.95 \(\rightarrow\) High pass.
\item coeff +0.95 \(\rightarrow\) Low pass.
\end{itemize}

The model.

\begin{lstlisting}[frame=single, caption=Live filtred delay model] 
SynthDef(\delfilt, {arg busIn=0, busOut=0,
                        maxdel=10, del=0.5, fbk=0.0,
                        mix=0, coef=0,
                        amp=0, gate=0, pan=0, done=2;
                    var in, local, sig, dly, env;
                        in    = In.ar(busIn);
                        local = LocalIn.ar(1);
                        sig   = in + local;
                        dly   = DelayL.ar(sig, maxdel, del);
                        dly   = OnePole.ar(dly,coef); // Filter
                        dly   = LeakDC.ar(dly);
                    LocalOut.ar(dly * fbk);      // Feedback sig
                        env = Linen.kr(gate,doneAction:done);
                        sig = XFade2.ar(dly, sig, mix);
                        sig = sig * env * amp;
                        sig = Pan2.ar(sig, pan);
                    Out.ar(busOut, sig)
                    }).add;
\end{lstlisting} 

Test it.

\begin{lstlisting}[frame=single] 
~fxBusIn = Bus.audio(s, 1); 

~source = Synth(\mic,  [\busIn,0, \busOut, ~fxBusIn, \amp,1], ~micGrp); 
~delay  = Synth(\delfilt, [\busIn,~fxBusIn, 
                           \busOut, 0, 
                           \maxdel, 4,
                           \del, 0.5, 
                           \fbk, 0.4,  
                           \coef,  0.95,
                           \amp,1, 
                           \gate, 1], ~fxGrp);  

~delay.set(\coeff, rand2(0.95).postln); // try to change
                     
s.defaultGroup.deepFree; ~fxBusIn.free; ~source.free; ~delay.free;
\end{lstlisting}

\subsubsection{Resonator}\label{resonator} 

Similar to the Karplus-Strong algorithm.

The model.

\begin{lstlisting}[frame=single, caption=Live resonator delay model] 
SynthDef(\resondel, {arg busIn=0, busOut=0, decayT=0.2, reson=0.01,
                         amp=0, gate=0, pan=0, done=2;
                     var in, dly, env, sig;
                         in    = In.ar(busIn);
                         reson = MouseY.kr(0.0001,0.01);
                         reson.reciprocal.poll(10);      // frequency
                         dly   = CombL.ar(in, 0.01, reson, decayT);
                         env   = Linen.kr(gate,doneAction:done);
                         sig   = dly * env * amp;
                         sig   = Pan2.ar(sig, pan);
                     Out.ar(busOut, sig)
                     }).add;
\end{lstlisting} 

Test it.

\begin{lstlisting}[frame=single] 
~fxBusIn = Bus.audio(s, 1); 

~source = Synth(\mic,  [\busIn,0, \busOut, ~fxBusIn, \amp,1], ~micGrp); 
~delay  = Synth(\resondel, [\busIn,~fxBusIn, 
                            \busOut, 0, 
                            \decayT, 0.2,
                            \reson, 0.01, 
                            \amp,1, 
                            \gate, 1], ~fxGrp); 

~delay.set(\reson, rrand(0.0001,0.01).postln);
                      
s.freeAll;
\end{lstlisting}

\subsection{Multichannel panning}\label{multichannel-panning}

How to position a monophonic signal in a two or three-dimensional space delimited in various ways by two or more loudspeakers.

Three possible ways of thinking about space in the use of stereophonic and multichannel diffusion systems:

\begin{itemize}
\tightlist
\item acoustic space within which to position the different monophonic sources.
   \begin{itemize}
   \tightlist
   \item listeners should not perceive the presence of the loudspeakers as if the sounds were coming from the walls of the concert hall.
   \item ambisonic, wavefield synthesis, bineural systems.
   \end{itemize}
\item loudspeakers are a sound diffusion tool with musical and historical value.
   \begin{itemize}
   \tightlist
   \item acousmonium, stereophonic, quadriphonic, and octophonic systems.
   \end{itemize}
\item loudspeakers take on the same value as individual acoustic instruments, characters or sound sculptures.
   \begin{itemize}
   \tightlist
   \item louspeakers as musical instruments.
   \end{itemize}
\end{itemize}

\begin{lstlisting}[frame=single] 
s.options.numOutputBusChannels_(8);
s.reboot;
s.plotTree;
s.scope;      
s.meter;
SynthDef(\ksig,{arg type=0, range=#[0,1], freq=1, busOut=0;
                var sig;
                    sig = Select.kr(type,
                                    [MouseX.kr(range[0], range[1]), // 0
                                     MouseY.kr(range[0], range[1]), // 1
                                     LFNoise1.kr(freq).range(range[0], range[1]), // 2
                                     LFSaw.kr(freq).range(range[0], range[1]),    // 3
                                     Impulse.kr(freq),              // 4
                                     Dust.kr(freq),                 // 5
                                     ]);
                    Out.kr(busOut,sig)
                    }).add;
\end{lstlisting}
   
If we want multichannels systems we must set it before booting Server.

\subsubsection{Mono, dual-mono and multi-mono panning}\label{mono-dual-mono-and-multi-mono}

Related to third typology \(\rightarrow\) loudspeaker as music instument.

In SuperCollider are represented with \textit{public out buses}.

Bus 0 \(\rightarrow\) leftmost loudspeakeer.

\begin{lstlisting}[frame=single] 
SynthDef(\out,{arg busOut = 0;
               var sig, env;
                   sig = SinOsc.ar;
                   env = Env.perc;
                   env = EnvGen.kr(env, 1, doneAction:2);
                   sig = sig * env;
               Out.ar(busOut, sig)
               }).add;

Synth(\out, [\busOut, rand(8)]);               
\end{lstlisting}

If we duplicate a monophonic signal by writing it on two adjacent channels \(\rightarrow\) dual mono.

In SuperCollider we can duplicate objects by \textit{!} shortcut.

\begin{lstlisting}[frame=single] 
SynthDef(\out2,{arg busOut = 0;
                var sig, env;
                    sig = SinOsc.ar;
                    env = Env.perc;
                    env = EnvGen.kr(env, 1, doneAction:2);
                    sig = sig * env;
                Out.ar(busOut, sig!2)
                }).add;

Synth(\out2, [\busOut, rand(8)]);            
\end{lstlisting}

Multi-monophonic diffusion systems lend themselves to interesting artistic expressive solutions of mirrored sounds and spatial sound references between amplified acoustic instruments and electroacoustic sounds.

\begin{center}
\includegraphics[scale=0.7]{speakers_3.png}
\end{center}

\subsubsection{Stereo}\label{stereo}

Two front speakers ideally positioned at a 60° angle to the optimal listening point.

\begin{center}
\includegraphics[scale=0.8]{stereo_angolo.png}
\end{center}

It is a one-dimensional frontal system mainly attributable to the first type of musical space types.

To obtain a stereo signal we must take a monophonic signal and distribute its amplitude between two adjacent channels.

To correct problems related to human perception the distribution is not linear.

In SuperCollider we can use the \textit{Pan2} UGen.

We can also simulate distance by acting on the amplitude of the signal.

Parameters are:
\begin{itemize}
\tightlist
\item position \(\rightarrow\) -1 to 1.
\item distance \(\rightarrow\) 0.001 to 1.
\item movement duration.
\end{itemize}

We can control them in the usual ways (MIDI, OSC, Envelopes, LFO, etc.).

\begin{center}
\includegraphics[scale=0.8]{stereo_1.png}
\end{center}

\begin{lstlisting}[frame=single, caption=Stereo pan model] 
SynthDef(\stereo, {arg pos=0,ptime=0,dis=1,gate=0;
                   var sig, env;
                       sig = SinOsc.ar(Rand(400,2000));
                       env = Linen.kr(gate,doneAction:2);
                       sig = sig * env;
                       sig = Pan2.ar(sig, pos.lag(ptime), dis.lag(ptime));
                   Out.ar(0, sig)
                   }).add;         
\end{lstlisting}

Test it

\begin{lstlisting}[frame=single, caption=Stereo pan model] 
~synth = Synth(\stereo, [\gate,1]);

~synth.set(\pos,rand2(1.0),\ptime,1);
~synth.set(\gate,0); 
\end{lstlisting}

\subsubsection{Quadriphony}\label{quadriphony}

Four speakers ideally placed at the corners of an imaginary square.

\begin{center}
\includegraphics[scale=0.8]{quadrifo.png}
\end{center}

Speaker numbering (L1 - L4) can be done in two ways:
\begin{itemize}
\tightlist
\item double stereo (left).
\item circular (right).
\end{itemize}

As in stereo systems we have to divide the amplitude of each source (monophonic signal) not over two but over four loudspeakers.

We define the square as a Cartesian plane on which we specify each point as x/y coordinates between 0.0 and 1.0.

\begin{center}
\includegraphics[scale=0.75]{quadrifo_1.png}
\end{center}

In SuperCollider we can use \textit{Pan4} UGen similar to \textit{Pan2}.

\begin{lstlisting}[frame=single, caption=Quadriphonic pan model] 
SynthDef(\quad, {arg xpos=0, ypos=0,ptime=0,gate=0;
                 var sig, env;
                     sig = SinOsc.ar(Rand(400,2000));
                     env = Linen.kr(gate,doneAction:2);
                     sig = sig * env;
                     sig = Pan4.ar(sig, xpos.lag(ptime), ypos.lag(ptime));
                 Out.ar(0, sig)
                 }).add;       
\end{lstlisting}

Test it.

\begin{lstlisting}[frame=single, caption=Stereo pan model] 
~synth = Synth(\quad, [\gate,1]);

~synth.set(\xpos,rand2(1.0),\ypos,rand2(1.0),\ptime,1) 
~synth.set(\gate,0); 
\end{lstlisting}

\subsubsection{Circular systems}\label{circular-systems}

Can be from 3 to 128 channels.

Five, six or eight are multichannel standards.

\begin{center}
\includegraphics[scale=0.65]{ottofo_1.png}
\end{center}

In SuperCollider we can use the \textit{PanAz} UGen.

Parameters are:
\begin{itemize}
\tightlist
\item n\_chans \(\rightarrow\) number of channels.
\item sig \(\rightarrow\) source (mono channel).
\item pos \(\rightarrow\) position - from 0.0 to 2.0
      \begin{itemize}
      \tightlist
      \item delta between two adiacent channels \(\rightarrow\) 2/n\_channels.
      \end{itemize}
\item level \(\rightarrow\) amplitude.
\item width \(\rightarrow\).
      \begin{itemize}
      \tightlist
      \item 2 \(\rightarrow\) spread between two adiacent channels.
      \item 4 \(\rightarrow\) spread between four adiacent channels.
      \item 6 \(\rightarrow\) spread between six adiacent channels.
      \item etc.
      \end{itemize}
\item orientation \(\rightarrow\) set leftmost bus channel.
      \begin{itemize}
      \tightlist
      \item 0.0 \(\rightarrow\) L1 - bus 0.
      \item 0.5 \(\rightarrow\) between L1 - bus 0.
      \end{itemize}
\end{itemize}

\begin{lstlisting}[frame=single, caption=Circular pan model] 
SynthDef(\circular, {arg pos=0, width=2, orient=0.5, gate=0;
                     var sig, env;
                         sig = SinOsc.ar(800);
                         env = Linen.kr(gate,doneAction:2);
                         sig = sig * env;
                         sig = PanAz.ar(8,  // numChans
                                        sig,
                                        pos, // 0 to 2
                                        1,   // level
                                        width,
                                        orient);
                     Out.ar(0, sig)
                     }).add;      
\end{lstlisting}

Test it.

\begin{lstlisting}[frame=single] 
~synth = Synth(\circular, [\gate,1]);

~pos = [0.0, 0.25, 0.50, 0.75, 1.00,  1.25,  1.50,  1.75]; // 0 to 2 
~pos = [0.0, 0.25, 0.50, 0.75, 1.00, -0.75, -0.50, -0.25]; // -1 to 1 is the same

r = Routine({
	        inf.do({arg i;
		            ~synth.set(\pos, ~pos.wrapAt(i));
		 	        1.wait
	                })
            }).reset.play;
\end{lstlisting}

Change orientation, see and listen.

\begin{lstlisting}[frame=single] 
~synth.set(\orient, 0);  // or 0.5
\end{lstlisting}

Change width, see and listen.

\begin{lstlisting}[frame=single] 
~synth.set(\orient, 0.5); 
~synth.set(\width, 2); // try 2, 4, 6 or 8

~synth.set(\gate,0); r.stop.free;
\end{lstlisting}

If we map a control signal (-1, 1) to the position we get circular or random movements depending on the type of signal.

\begin{lstlisting}[frame=single] 
~kbus = Bus.control(s,1);

~ksig  = Synth(\ksig,  [\type, 3, \range, [-1, 1], \freq, 0.2, \busOut, ~kbus]); 
~synth = Synth(\circular, [\pos, ~kbus.asMap, \gate,1]);

~ksig.set(\type, 0); // mouse x
~ksig.set(\type, 2); // random zig zag
~synth.set(\gate,0); ~ksig.free; ~kbus.free;
\end{lstlisting}

\section{Composition sketches proposal}\label{composition-sketches-proposal}

Design and realize a work for a live source and electronic sounds.

Combinations can be:
\begin{itemize}
\tightlist
\item instrument and pre-recorded sounds.
\item instrument and live computer-generated sounds.
\item instrument and live processing.
\end{itemize}

By instrument we mean:
\begin{itemize}
\tightlist
\item musical instrument from any culture.
\item voice (sung or recited). 
\item any type of acoustic source.
\end{itemize}

The work can be in the form of:
\begin{itemize}
\tightlist
\item art music composition.
\item improvisation.
\item installation.
\item sound art project (sound-sculpture or site specific soundscape).
\end{itemize}
